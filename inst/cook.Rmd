---
title: "cooking"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Suppose there are five people in a family.  Each day for five days,
one person cooks a meal.  After the fifth day, each person puts the
meals in order of preference, but is not allowed to vote on their own
meal.  This very short vignette shows how to apply generalized
Bradley-Terry to this situation using the `hyper2` package.

```{r cars}
library(hyper2)
H <- hyper2(pnames=paste("p",1:5,sep=""))
H
```

Now add some data:

```{r}
H <- H +
    order_likelihood(c(5,2,3,4)) + # person 1 says 5 is the best, 4 the worst.
    order_likelihood(c(1,5,3,4)) + # person 2 says 1 is the best, 4 the worst.
    order_likelihood(c(1,4,2,5)) + # person 3 says 1 is the best, 5 the worst.
    order_likelihood(c(1,2,3,5)) + # person 4 says 1 is the best, 5 the worst.
    order_likelihood(c(2,1,3,4))   # person 5 says 2 is the best, 4 the worst.
H
```

Note that noone is allowed to vote for themselves.  We may find
maximum likelihood estimate for the strengths,
$\operatorname{argmax}\mathcal{L}\left(p_1,\ldots,p_5\right)$:

```{r}
maxp(H)
```

Graphically:

```{r maxlike, echo=FALSE}
dotchart(maxp(H),main="probabilities")
dotchart(log(maxp(H)),main="log probabilities")
```

We can assess the hypothesis that all players have the same strength:

```{r} 
L1 <- loglik(H,indep(equalp(H)))  # support at equal strengths
L2 <- loglik(H,indep(maxp(H)))    # maximum support
L2-L1
pchisq(2*(L2-L1),df=1,lower.tail=FALSE) # p-value of asymptotic distribution
```

Now we can assess the hypothesis that person `a` does in fact have the
highest strength of the five.  We can follow the reasoning in the
_icons_ demonstration:

```{r}
o <- function(Ul,Cl,startp,give=FALSE){
    small <- 1e-5  #  ensure start at an interior point
    if(missing(startp)){startp <- small*(1:4)+rep(0.1,4)}
    out <- maxp(H, startp=small*(1:4)+rep(0.1,4), give=TRUE, fcm=Ul,fcv=Cl)
		if(give){
			return(out)
		} else {
			return(out$value)
		}
}

p2max <- o(c(-1, 1, 0, 0), 0)
p3max <- o(c(-1, 0, 1, 0), 0)
p4max <- o(c(-1, 0, 0, 1), 0)
p5max <- o(c(-2,-1,-1,-1),-1)
```

(the final line is different because `p5` is the fillup value).

```{r}
(likes <- c(p2max,p3max,p4max,p5max))
max(likes)
```

Observe that the hypothesis with the maximum likelihood is
$p_2\geqslant p_1$, as might be expected on the grounds that in the
unconstrained case we have
$\hat{p_2}>\max\left(\hat{p_3},\hat{p_4},\hat{p_5}\right)$.  Now
compare the constrained maximum with the unconstrained maximum:

```{r}
maxp(H,give=TRUE)$value
```

So the support loss by the constraint is

```{r}
(L <- maxp(H,give=TRUE)$value - max(likes))
```

short of Edwards's two-units-of-support criterion.  There is no strong
evidence to support the assertion that person 1 is actually stronger
than person 2 in the sense that $p_1>p_2$.

## Suspect observation

Suppose that we subsequently observe order statistic `5,4,3,2,1`, that
is, person 5 is the best, 4 is the second best, and so on to 1 being
the worst.  Is this observation consistent with the previous dataset?

It is possible to perform a permutation test on this as follows.
First, calculate the probability of each of the $5!=120$ possible
observations (up to a constant):

```{r}
library(partitions)
imH <- indep(maxp(H))
f <- function(o){loglik(order_likelihood(o),imH,log=FALSE)}
LL <- apply(perms(5),2,f)
```

Then calculate the pvalue as the probability of obtaining the
observation or an observation more extreme:


```{r}
obs <- c(5,4,3,2,1)
(pval <- sum(LL[LL <= f(obs)])/sum(LL))
```

# Just the loser


Now we are going to look at what happens when our observation is only
the _loser_ (which is always me).  We have six competitors
`a,b,c,d,e,f` with nonnegative strengths $p_1,p_2,p_3,p_4,p_5,p_6,
\sum p_i=1$.  I am competitor `a` with strength $p_1$, and always
lose.  We have two hypotheses:

* $H_1\colon p_1=0$
* $H_2\colon\exists i\neq 1 \mbox{ with } p_1\geq p_i>0$

(observe that $H_2$ implies that someone is worse than me).  Both
hypotheses correspond to a restriction on allowable parameter space.
The first step is to define a suitable likelihood function for our
observation:

```{r}
n <- 6 # number of people in the family
H <- hyper2(pnames=letters[1:6])
L <- ggol(H,letters[2:n],letters[1])
length(L)
L[[1]]
L[[2]]
```

In the above, `L` is a list of hyper2 objects corresponding to all
$5!=120$ possible observed order statistics (only the first two,
`L[[1]]` and `L[[2]]`, are printed, which correspond to orders
`bcdefa` and `bcdfea` respectively).  Any order is permissible, so
long as player `a` (me) is bottom.  Now we maximize the likelihood
under $H_1$, that is, perform an unconstrained maximization:

```{r}
(ans_unconstrained <- maxplist(L,give=TRUE))
```

The constraint embodied in $H_1$ does not need to be enforced: the
evaluate $\hat{p}$ has $p_1=0$, consistent with competitor `a` coming
last; actually we have
$\hat{p}=\left(0,\frac{1}{5},\frac{1}{5},\frac{1}{5},\frac{1}{5},\frac{1}{5}\right)$
analytically, and the numerics are not too far from this.  The
likelihood at the evaluate is 1 (technically, this is wrong because
likelihood is defined only up to a multiplicative constant.  A correct
statement is: the likelihood function evaluated by
`like_single_list()` returns 1).  The next step is to perform a
constrained maximization, the constraint being that I am better than
at least one other person, here chosen to be, without loss of
generality, competitor `b`:

```{r}
small <- 1e-2  # numerical necessity
ans_constrained <-
maxplist(L,startp=c(small*2,rep(small,n-2)),fcm=rbind(c(1,-1,rep(0,n-3))),fcv=0,give=TRUE)
ans_constrained
```

Observe that the constraint is active: $p_1=p_2$ in the numerical
result.  Analytically, the evaluate is indeterminate in
$p_3,p_4,p_5,p_6$, but has $p_1=p_2=0$ (numerically this means that
$p_1=p_2=\epsilon$).  We can see that the likelihood ratio ${\mathcal
L}(H_2)/{\mathcal L}(H_1)$ is 0.5 for an observation that I come last.
This is exactly the same as the likelihood ratio for the following
situation: we toss a coin which is either fair ($H_\mbox{fair}$) or
two-headed ($H_\mbox{2heads}$).  We observe a head.  Then ${\mathcal
L}(H_\mbox{2heads})/{\mathcal L}(H_\mbox{fair}) = 0.5$ as well (this
is Edwards's valet and black and white ball thought experiment).
