---
title: "Domestic cooking and likelihood"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Suppose there are five people in a family.  Each day for five days,
one person cooks a meal.  After the fifth day, each person considers
the four meals cooked by other family members, and puts them in order
of preference.  This very short vignette shows how to apply
generalized Bradley-Terry to this situation using the `hyper2`
package.

```{r loadlib}
library(hyper2)
H <- hyper2(pnames=paste("p",1:5,sep=""))
H
```

Now add some data:

```{r data}
H <- H +
    order_likelihood(c(5,2,3,4)) + # person 1 says 5 is the best, 4 the worst.
    order_likelihood(c(1,5,3,4)) + # person 2 says 1 is the best, 4 the worst.
    order_likelihood(c(1,4,2,5)) + # person 3 says 1 is the best, 5 the worst.
    order_likelihood(c(1,2,3,5)) + # person 4 says 1 is the best, 5 the worst.
    order_likelihood(c(2,1,3,4))   # person 5 says 2 is the best, 4 the worst.
H
```

Note that noone is allowed to vote for themselves.  We may find
maximum likelihood estimate for the strengths,
$\operatorname{argmax}\mathcal{L}\left(p_1,\ldots,p_5\right)$:

```{r}
maxp(H)
```

Graphically:

```{r maxlike, echo=FALSE}
dotchart(maxp(H),pch=16,main="probabilities")
dotchart(log(maxp(H)),pch=16,main="log probabilities")
```

We can assess the hypothesis that all players have the same strength:

```{r}
L1 <- loglik(indep(equalp(H)),H)  # support at equal strengths
L2 <- loglik(indep(maxp(H)),H)    # maximum support
L2-L1
pchisq(2*(L2-L1),df=1,lower.tail=FALSE) # p-value of asymptotic distribution
```

Thus we reject the hypothesis of equal strength.  Now we can assess
the hypothesis that person `a` does in fact have the highest strength
of the five.  We can follow the reasoning in the _icons_
demonstration:

```{r}
o <- function(Ul,Cl,startp,give=FALSE){
    small <- 1e-4  #  ensure start at an interior point
    if(missing(startp)){startp <- small*(1:4)+rep(0.1,4)}
    out <- maxp(H, startp=small*(1:4)+rep(0.1,4), give=TRUE, fcm=Ul,fcv=Cl)
		if(give){
			return(out)
		} else {
			return(out$value)
		}
}

p2max <- o(c(-1, 1, 0, 0), 0)
p3max <- o(c(-1, 0, 1, 0), 0)
p4max <- o(c(-1, 0, 0, 1), 0)
p5max <- o(c(-2,-1,-1,-1),-1)
```

(the final line is different because `p5` is the fillup value).

```{r}
(likes <- c(p2max,p3max,p4max,p5max))
max(likes)
```

Observe that the hypothesis with the maximum likelihood is
$p_2\geqslant p_1$, as might be expected on the grounds that in the
unconstrained case we have
$\hat{p_2}>\max\left(\hat{p_3},\hat{p_4},\hat{p_5}\right)$.  Now
compare the constrained maximum with the unconstrained maximum:

```{r}
maxp(H,give=TRUE)$value
```

So the support loss by the constraint is

```{r}
(L <- maxp(H,give=TRUE)$value - max(likes))
```

short of Edwards's two-units-of-support criterion.  There is no strong
evidence to support the assertion that person 1 is actually stronger
than person 2 in the sense that $p_1>p_2$.

## Suspect observation

Suppose that we subsequently observe order statistic `5,4,3,2,1`, that
is, person 5 is the best, 4 is the second best, and so on to 1 being
the worst.  Is this observation consistent with the previous dataset?

It is possible to perform a permutation test on this as follows.
First, calculate the probability of each of the $5!=120$ possible
observations (up to a constant):

```{r}
library(partitions)
imH <- indep(maxp(H))
f <- function(o){loglik(imH,order_likelihood(o),log=FALSE)}
LL <- apply(perms(5),2,f)
length(LL)
sum(LL)
head(LL)
```

So `LL` is the probability of observing each permutation of 5 objects.
We then calculate the $p$-value as the probability of obtaining the
observation or an observation more extreme; in this case we define a
permutation to be "more extreme" if it has a smaller probability than
the observed permutation of `5,4,3,2,1` (under the null).  This is
easily calculated:

```{r}
obs <- c(5,4,3,2,1)
(pval <- sum(LL[LL <= f(obs)])/sum(LL))
```

Thus it is reasonable to reject the hypothesis that this particular
observation was drawn from the same distribution as the others, and
infer that it was suspect.


## Changes in cooking strength.

We now consider a sequence of observations where one person, say
person 1, is suspected of an increase in strength (perhaps they
attended a domestic cookery course).  We make some observations before
and after the training and seek evidence that it was effective.
Unlike the previous cases, here we have a full order statistic without
the complication of not being allowed to vote for oneself (perhaps a
professional chef puts the dishes in order).  First, before:

```{r,beforetraining}
H <- hyper2(pnames=c(paste("p",1:5,sep=""),"t"))  # 't' the strength of training
# observations before training:
Hbefore <- H +
    order_likelihood(c(5,2,3,4,1)) + #  5 is the best, 4 the worst.
    order_likelihood(c(5,3,2,4,1)) + #  5 is the best, 1 the worst.
    order_likelihood(c(4,5,3,2,1)) + #  4 is the best, 1 the worst.
    order_likelihood(c(5,3,4,1,2)) + #  5 is the best, 2 the worst.
    order_likelihood(c(2,5,3,1,4))   #  2 is the best, 4 the worst.
Hbefore
```

Now, after the training we have two order observations: `1,2,3,4,5`
and `3,1,5,2,4`.  Thus player 1 comes first and second (after player
3) respectively.  The likelihood for the first would be

\[
\frac{p_1+t}{p_1+t+p_2+p_3+p_4+p_5}\cdot
\frac{p_2  }{      p_2+p_3+p_4+p_5}\cdot
\frac{p_3  }{          p_3+p_4+p_5}\cdot
\frac{p_4  }{              p_4+p_5}\cdot
\frac{p_5  }{                  p_5}\cdot
\]

and the likelihood for the second would be

\[
\frac{p_3  }{p_1+t+p_2+p_3+p_4+p_5}\cdot
\frac{p_1+t}{p_1+t+p_2+    p_4+p_5}\cdot
\frac{p_5  }{      p_2+    p_4+p_5}\cdot
\frac{p_2  }{      p_2+    p_4    }\cdot
\frac{p_4  }{              p_4    }\cdot
\]


We can translate these into package idiom by defining likelihood
functions `H1after` and `H2after` for the two observations:


```{r,aftertraining1}
H1after <- H
H1after[c("p1","t")] %<>% inc()
H1after[  "p2"     ] %<>% inc()
H1after[  "p3"     ] %<>% inc()
H1after[  "p4"     ] %<>% inc()
H1after[  "p5"     ] %<>% inc()
H1after[c("p1","t","p2","p3","p4","p5")] %<>% dec()
H1after[c(         "p2","p3","p4","p5")] %<>% dec()
H1after[c(              "p3","p4","p5")] %<>% dec()
H1after[c(                   "p4","p5")] %<>% dec()
H1after[c(                        "p5")] %<>% dec()
H1after
```

```{r,aftertraining2}
H2after <- H
H2after[  "p3"     ] %<>% inc()
H2after[c("p1","t")] %<>% inc()
H2after[  "p5"     ] %<>% inc()
H2after[  "p2"     ] %<>% inc()
H2after[  "p4"     ] %<>% inc()
H2after[c("p1","t","p2","p3","p4","p5")] %<>% dec()
H2after[c("p1","t","p2",     "p4","p5")] %<>% dec()
H2after[c(         "p2",     "p4","p5")] %<>% dec()
H2after[c(         "p2",     "p4"     )] %<>% dec()
H2after[c(                   "p4"     )] %<>% dec()
H2after
```

Combine:

```{r,combineboth}
(Htot <- Hbefore + H1after + H2after)  # observations are independent!
(ML_unconstrained <- maxp(Htot))
```

We see the training entity has an estimated strength of about 0.63,
higher than all real players combined.  At the evaluate the
loglikelihood is

```{r,loglikateval}
loglik(indep(ML_unconstrained),Htot)
```

We can test the hypothesis that the training was ineffective by
constraining the optimization to $t=0$:

```{r}
small <- 1e-4
(ML_constrained <- maxp(Htot,startp=rep(0.2*(1-small*2.1),5),fcm=c(1,1,1,1,1),fcv=1-2*small))
loglik(indep(ML_constrained),Htot)
```

[as a consistency check we can perform the same calculation with a
slightly different value for `small`:


```{r}
small <- 2e-4  # cf 1e-4 previously
ML_constrained <- maxp(Htot,startp=rep(0.2*(1-small*2.1),5),fcm=c(1,1,1,1,1),fcv=1-2*small)
loglik(indep(ML_constrained),Htot) # cf -29.973 previously
```

and we can see that this is almost the same].  Thus, the support for
our alternative hypothesis would be

```{r}
loglik(indep(ML_unconstrained),Htot)-loglik(indep(ML_constrained),Htot)
```

thus exceeding Edwards's two units of support.  We have strong
evidence to suggest that the training was effective.

