---
title: "Analysis of pudding following Davidson 1970"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
set.seed(0)
knitr::opts_chunk$set(echo = TRUE)
library("hyper2")
library("magrittr")
library("PlackettLuce")
library("partitions")
options("digits" = 5)
```

<p style="text-align: right;">
![](`r system.file("help/figures/hyper2.png", package = "hyper2")`){width=10%}
</p>

This short document creates the `pudding` suite of R objects and
presents some preliminary analysis.  It follows Davidson 1970 and the
`PlackettLuce` package.

Here is the pudding result:

```{r}
pudding_table <- pudding  # standard hyper2 terminology
pudding_table
```

Here is a method to convert the pudding matrix to a likelihood function:


```{r,cache=TRUE}

    numbers <- as.character(1:6)
    puddings <- paste("pudding",numbers,sep="_")
    tyers    <- paste("tie",numbers,sep="_")

`convert` <- function(M){

    H <- hyper2()
    I <- hyper2()
    J <- hyper2()
    for(i in seq_len(nrow(M))){
        r_ij <- M[i,3]
        w_ij <- M[i,4]
        w_ji <- M[i,5]
        t_ij <- M[i,6]
        H[c(puddings[c(M[i,1]       )]      )] %<>% inc(w_ij)
        H[c(puddings[c(       M[i,2])]      )] %<>% inc(w_ji)
        H[c(                           "tie")] %<>% inc(t_ij) 
        H[c(puddings[c(M[i,1],M[i,2])],"tie")] %<>% dec(r_ij)
        
        I[c(puddings[c(M[i,1]       )]      )] %<>% inc(w_ij)
        I[c(puddings[c(       M[i,2])]      )] %<>% inc(w_ji)
        I[c(tyers   [c(M[i,1],M[i,2])]      )] %<>% inc(t_ij)
        I[c(puddings[c(M[i,1],M[i,2])],tyers[c(M[i,1],M[i,2])])] %<>% dec(r_ij)    

        J[c(puddings[c(M[i,1]       )],"first")] %<>% inc(w_ij)
        J[c(puddings[c(       M[i,2])]        )] %<>% inc(w_ji)
        J[c(tyers   [c(M[i,1],M[i,2])]        )] %<>% inc(t_ij)
        J[c(puddings[c(M[i,1],M[i,2])],tyers[c(M[i,1],M[i,2])],"first")] %<>% dec(r_ij)
    }

    return(list(H,I,J))
}
```

Now use it:


```{r calculatelikelihoodfunctionsandmaximize,cache=TRUE}
lf <- convert(pudding_table)
pudding <- lf[[1]] # standard hyper2 terminology
pudding2 <- lf[[2]]
pudding3 <- lf[[3]]
pudding_maxp  <- maxp(pudding)
pudding2_maxp <- maxp(pudding2)
pudding3_maxp <- maxp(pudding3)
```

```{r}
pudding_maxp
pudding2_maxp
pudding3_maxp
```

# Pudding 1

We will analyse `pudding` first:

```{r}
summary(pudding)
pie(pudding_maxp)
```

First we use `pudding` to test a null of equal pudding strengths:

```{r,puddingtest,cache=TRUE}
samep.test(pudding,puddings)
```

so according to `samep.test()` the puddings are all the same strength.

# Pudding 2

Object `pudding2` includes a pudding-specific propensity to tie.  We
can test different nulls:

```{r,m2test,cache=TRUE}
samep.test(pudding2,puddings)
samep.test(pudding2,tyers)
```

# Pudding 3

Object `pudding3` includes a first-mover advantage:

```{r}
summary(pudding3)
pudding3_maxp
```



# Davidson's analysis 

Davidson (1970) considers the following probability model:

\[
\operatorname{Prob}(i\succ j) = \frac{\pi_i}{\pi_i+\pi_j+\nu\sqrt{\pi_i\pi_j}}\\
\operatorname{Prob}(j\succ i) = \frac{\pi_j}{\pi_i+\pi_j+\nu\sqrt{\pi_i\pi_j}}\\
\operatorname{Prob}(i\sim  j) = \frac{\nu\sqrt{\pi_i\pi_j}}{\pi_i+\pi_j+\nu\sqrt{\pi_i\pi_j}}
\]

and gives the following estimate for the pudding data:

```{r}
davidson <- c(0.1388005,0.1729985, 0.1617420, 0.1653930, 0.1586805, 0.2023855, 0.7468147)
names(davidson) <- c(puddings,"tie")
davidson
par(pty='s')
plot(davidson[1:6],pudding_maxp[1:6]/(1-pudding_maxp[7]),asp=1,xlim=c(0.13,0.2),ylim=c(0.13,0.2),pch=16)
abline(0,1)
```

Although the probability model is different, we may compare the
probabilities of $i\succ j$, $j\succ i$, and $i\sim j$ for $i<j$ with
the two models.  This gives us a total of $3{6\choose 2}=45$
(nonindependent) probabilities and we may plot a scattergraph:

```{r,davidsonvshyper2,cache=TRUE}
ph <- pudding_maxp # ph == 'pudding hankin'; saves typing
pd <- davidson     # pd == 'pudding davidson'
print(ph)
print(pd)

`hankin` <- function(ph){
  ##  ph a vector of length n+1; first n entries are strengths, last one
  ##  propensity to tie
  n <- length(ph)-1
  m <- allbinom(n,2)
  out <- matrix(NA,nrow=ncol(m),ncol=3)
  colnames(out) <- c("i","j","tie")
  rownames(out) <- apply(m,2,paste,collapse="")
  th <- ph[n+1]
  for(o in seq_len(ncol(m))){
      i <- m[1,o]
      j <- m[2,o]
      dh <- ph[i] + ph[j] + th    # dh == 'denominator hankin'
      out[o,1] <- ph[i]/dh
      out[o,2] <- ph[j]/dh
      out[o,3] <- th/dh
  }
  return(out)
}  

`davidson` <- function(pd){

  ##  pd a vector of length n+1; first n entries are strengths, last one
  ##  nu
  n <- length(pd)-1  # how many puddings
  nu <- pd[n+1]  
  m <- allbinom(n,2)
  out <- matrix(NA,nrow=ncol(m),ncol=3)
  colnames(out) <- c("i","j","tie")

  rownames(out) <- apply(m,2,paste,collapse="")

  nu <- pd[n+1]

  for(o in seq_len(ncol(m))){
      i <- m[1,o]
      j <- m[2,o]
      dd <- pd[i] + pd[j] + nu*sqrt(pd[i]*pd[j])  # dd == 'denominator davidson'
      out[o,1] <- pd[i]/dd
      out[o,2] <- pd[j]/dd
      out[o,3] <- nu*sqrt(pd[i]*pd[j])/dd
  }
  return(out)
}

plotter <- function(ph,pd,...){
  h <- hankin(ph)
  d <- davidson(pd)
  nh <- nrow(h)
  plot(c(h),c(d),pch=16,asp=1,col=c(rep("red",nh),rep("blue",nh),rep("green",nh)),...)
}
```

```{r}
print(ph)
print(hankin(ph))
print(pd)
print(davidson(pd))
jj <- c(2,5)/10
par(pty='s')
plotter(ph,pd,xlim=jj,ylim=jj)
grid()
```


Now calculate likelihoods:

```{r}
n <- pudding_table[,-(1:3),]
h <- hankin(ph)
d <- davidson(pd)
n
h
d
sum(n*log(h))
sum(n*log(d))
sum(n*log(h))-sum(n*log(d))
```


# Appendix:  synthetic datasets

Above we see that, according to this model, there is no evidence to
suggest that the puddings' strengths, or their tying ability, differ.
But we can adduce a dataset for which the tying ability _does_ differ.
Consider this:

```{r, makem}
p <- pudding_table
p[1 ,4:6] <- c(10,10,37)  # 1v2
p[2 ,4:6] <- c(10,10,27)  # 1v3
p[4 ,4:6] <- c(10,10,24)  # 1v4
p[7 ,4:6] <- c(10,10,20)  # 1v5
p[11,4:6] <- c(10,10,31)  # 1v6
p
```

(above, we doctor the dataset so that any comparison involving pudding
1 has a high probability of tying).

Then:

```{r,tiepud,cache=TRUE}
Hp <- convert(p)[[2]]
mHp <- maxp(Hp)
mHpt <- mHp[7:12]  #just the tyers
```

visualise:

```{r}
mHpt
plot(mHpt)
```

(above we see that pudding 1 does indeed have a higher tie
probability).  Test the null of equal tying probabilities:

```{r,thptest,cache=TRUE}
(tHp <- samep.test(Hp,tyers))
```

Further, test the null the pudding 1 has zero tying probability:

```{r,thpzero,cache=TRUE}
(tHpzero <- specificp.test(Hp,"tie_3"))
```

## Test of Davidson vs Hankin

Although the likelihood for Davidson's model was higher than mine for
the original dataset, we can create a synthetic dataset which is a
random observation drawn from a reified Bradley-Terry probability
model.  I will then test the hypothesis that the data is in fact drawn
from an RBT distribution by calculating a likelihood ratio.

```{r,synthmaker}
set.seed(2)
f <- function(i){rmultinom(1,50,prob=h[i,])} # f(i) = sample from row i of h
synth <- pudding_table
synth[,-(1:3)] <- t(sapply(1:15,f))  # random sample
synth[,3] <- 50
rownames(synth) <- rownames(p)
colnames(synth) <- colnames(p)
synth
```

Above, `synth` is a dataset drawn from an RBT model with maximum
likelihood parameters obtained from the original dataset.  We now use
both methods.  First reified Bradley-Terry:

```{r,useboth,cache=TRUE}
(H_synth <- convert(synth)[[1]])
ph_synth <- maxp(H_synth)
```

```{r}
ph_synth
```

The above strengths are different from (but not too different from)
the value obtaine from `maxp(H)` above.  Now analyse the same dataset
but using the method given in the `PlackettLuce` vignette:

```{r}
PlackettLuce_coef <- function(pudding_table){
i_wins <- data.frame(Winner = pudding_table$i, Loser = pudding_table$j)
j_wins <- data.frame(Winner = pudding_table$j, Loser = pudding_table$i)
  ties <- data.frame(Winner = asplit(pudding_table[c("i", "j")], 1),
                     Loser = rep(NA, 15))
R <- as.rankings(rbind(i_wins, j_wins, ties),
                 input = "orderings")
w <- unlist(pudding_table[c("w_ij", "w_ji", "t_ij")])
mod <- PlackettLuce(R, weights = w, npseudo = 0, maxit = 7)
return(coef(mod,log=FALSE))
}	
```

As a consistency check, try verifying the original result:

```{r,verifypl,cache=TRUE}
PlackettLuce_coef(pudding_table)
```

Above, we see values that match those in the `PlackettLuce` vignette.
Now apply the same method to the synthetic dataset `synth`:

```{r,calcpdsynth,cache=TRUE}
(pd_synth <- PlackettLuce_coef(synth))
```

Now we need to calculate the probabilities:

```{r}
(h_synth <- hankin(ph_synth))
(d_synth <- davidson(pd_synth))
```

And calculate a likelihood ratio for the two hypotheses, RBT and
Davidson:

```{r}
(n <- synth[,-(1:3),])
(lh_synth <- sum(n*log(h_synth)))
(ld_synth <- sum(n*log(d_synth)))
lh_synth - ld_synth
```

So reified Bradley-Terry is better than Davidson, but (in this case at
least) not by much.

# References

* R. D. Davidson 1970. "On extending the Bradley-Terry model to accommodate ties in paired comparison experiments".  _Journal of the American Statistical Association_, Volume 65, Number 329, pp317--328


### Package dataset

Following lines create `pudding.rda`, residing in the `data/` directory of the package.

```{r,label=savecurlingdataset}
save(pudding_table,pudding,pudding_maxp,curling2_maxp,file="pudding.rda")
```
