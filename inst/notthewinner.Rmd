---
title: "Weakly informative observations: not the winner"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(hyper2)
```

# Partial rank observations: someone didn't win

Here we consider a situation in which we make an observation that is
only very very weakly informative.  We consider the observation
${\mathcal O}$ that a particular player *does not* win: the order
statistic is unobserved and we know nothing about it except for the
fact that (wlog) player 1 ($p_1$, aka "me") is not first placed.  We
consider whether there is evidence to support two different assertions:

* $H_1\colon p_1=p_2=\ldots=p_n=\frac{1}{n}$
* $H_2\colon\exists i\neq 1 \mbox{ with } p_1\geq p_i>0$

Our alternative would be that $(p_1,\ldots,p_n) is unconstrained
except for the unit sum constraint:

* $H_0\colon\sum p_i=1$  (that is, no restriction)

(see how $H_2$ implies that someone is worse than me).  Observe that
$H_1$ and $H_2$ correspond to a restriction on allowable parameter
space.  To understand the informativeness of ${\mathcal O}$, we will
consider it in conjunction with some highly informative observations
${\mathcal I}$ which are order statistics:

```{r}
(H <- hyper2(pnames=paste("p",1:5,sep="")) +
    rank_likelihood(c(5,2,1,4)) + 
    rank_likelihood(c(2,4,1)) + 
    rank_likelihood(c(4,3,1)) + 
    rank_likelihood(c(3,5)))
	```
	
We will firstly consider these observations in isolation, then later
combine them with ${\mathcal O}$ which we will take to be
(conditionally) independent.  The first step is estimate the players'
strengths:

```{r}	
(mH0 <- maxp(H))
loglik(indep(mH0),H)
```

Above, `mH0` corresponds to an unconstrained optimization.  Note the
low but nonzero estimated strength of `p_1`.  Observe in passing that
we may reject $H_z\colon p_1=0$ unconditionally: we can deduce using
elementary arguments that the likelihood of $H_z$ is zero: if $p_1=0$,
then $p_4=0$ from the first line [because $p_4$ beat $p_1$ on that
occasion], and then $p_1=0$ from line 2; then $p_3=0$ from line 3,
$p_5=0$ from line 4 and finally $p_2=0$ from line 1.  Thus we can say
for sure that $H_z$ is incorrect and we may safely ignore it
henceforth.

## Hypothesis 1: equality


```{r}
equalp.test(H)
```

Thus there is no evidence to suggest that the players have different
strengths: we are unable to reject $H_1$, the hypothesis of equality.
Hypothesis $H_2$ is rather tricky so we will use the ersatz
alternative that $p_1\geqslant p_4$ (we choose $p_4$ on the grounds of
its low estimated value).  Then

```{r}
n <- 5 # number of players
small <- 1e-3  # numerical necessity
(mH1 <- maxp(H,startp=c(small*2,rep(small,n-2)),fcm=rbind(c(1,0,0,-1)),fcv=0))
loglik(indep(mH1),H)
loglik(indep(mH0),H)-loglik(indep(mH1),H)   # support
```

There is no reason to reject our null that $p_1\geqslant p_4$, for the
support falls below the two units of support criterion.  Further, see
how the constraint is active, for at the evaluate $p_1=p_4$ (the
numerical value of `small` is immaterial).

# Additional uninformative observation

Suppose we now make a perfectly uninformative observation: in an
independent trial, the order statistic for the five competitors was
one of the $5!=120$ possible orders.  How does this change our
relative support for $H_0$ against $H_1$ and $H_2$?  It should make no
difference.

```{r,uninformativesupportfunction}
library("partitions")
H # as before, here for convenience
M <- perms(5)   # uninformative!
SL <- list()
for(i in seq_len(ncol(M))){
	SL[[i]] <- H + rank_likelihood(M[,i,drop=TRUE])
}
SL <- as.suplist(SL)
```

So `SL` is a compound object that gives a likelihood function for the
joint observation of the order statistics and the uninformative data a
subsequent (independent) trial was in any of the $5!=120$ possible
orders.  We can find the MLE for different observations:

```{r,mls0,cache=TRUE}
mSL0 <- maxp(SL)
mSL1 <- maxp(SL,startp=c(small*2,rep(small,n-2)),fcm=rbind(c(1,0,0,-1)),fcv=0)
mSL2 <- equalp(SL)
```

We use `like_single_list()` to calculate the likelihoods at the
different evaluates; note that this function returns likelihoods, not
supports.

```{r,supp2calc}
Supp2 <-
      log(c(
      H0 = like_single_list(indep(mSL0),SL),
      H1 = like_single_list(indep(mSL1),SL),
      H2 = like_single_list(indep(mSL2),SL)))
(Supp2 <- Supp2-max(Supp2))
```

which is identical to the previous support function for $H_1$ and
$H_2$ (apart from a traditional sign) taken from `equalp.test()` and
`mSL2` above.

# Additional weakly informative observation

Now we make another observation ${\mathcal O}$ which is independent of
${\mathcal I}$: person `1` did not win.  It is clear that observation
${\mathcal O}$ is only very weakly informative.  Package idiom is
similar to the perfectly uninformative observation considered above,
except that we remove every order that has person 1 winning:

```{r,slacalc}
M <- perms(5)
M <- M[, M[1,]!=1]  # remove any column with "1" in first place
SLa <- list()
for(i in seq_len(ncol(M))){
	SLa[[i]] <- H + rank_likelihood(M[,i,drop=TRUE])
}
SLa <- as.suplist(SLa)
```

So `SLa` is a compound object that gives a support function for the
joint observation ${\mathcal I}$ and ${\mathcal O}$.  We can find the
MLE:

```{r,mlsa,cache=TRUE}
mSLa0 <- maxp(SLa)
mSLa1 <- maxp(SLa,startp=c(small*2,rep(small,n-2)),fcm=rbind(c(1,0,0,-1)),fcv=0)
mSLa2 <- equalp(SLa)
```

```{r,suppacalc}
Suppa <-
      log(c(
      H0 = like_single_list(indep(mSLa0),SLa),
      H1 = like_single_list(indep(mSLa1),SLa),
      H2 = like_single_list(indep(mSLa2),SLa)))
(Suppa <- Suppa-max(Suppa))
```

We can now compare the support function for ${\mathcal I}$ with the
support function for ${\mathcal I}$ and ${\mathcal H}$:

```{r,comparesups}
Supp2-Suppa
```

Thus ${\mathcal O}$ furnishes a tiny bit of extra evidence against
$H_1$ (about $0.016$ units of support) and a little bit of extra
evidence against $H_2$ (about $0.193$ units of support).
