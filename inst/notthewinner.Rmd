---
title: "Weakly informative observations: not the winner"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(hyper2)
```


# Partial rank observations: someone didn't win

Here we consider a situation in which we make an observation that is
only very very weakly informative.  We consider the observation
${\mathcal O}$ that a particular player *does not* win: the order
statistic is unobserved and we know nothing about it except for the
fact that (wlog) player 1 (aka "me") is not first placed.

As in `loser.Rmd`, we have three hypotheses:

* $H_0\colon\sum p_i=1$  (that is, no restriction)
* $H_1\colon\exists i\neq 1 \mbox{ with } p_1\geq p_i>0$
* $H_2\colon p_1=p_2=\ldots=p_n=\frac{1}{n}$

(see how $H_1$ implies that someone is worse than me).  Observe that
$H_1$ and $H_2$ correspond to a restriction on allowable parameter
space. 

To understand the informativeness of ${\mathcal O}$, we will consider
it in conjunction with some highly informative observations ${\mathcal
I}$ which are order statistics:

```{r}
(H <- hyper2(pnames=paste("p",1:5,sep="")) +
    order_likelihood(c(5,2,1,4)) + 
    order_likelihood(c(2,4,1)) + 
    order_likelihood(c(4,3,1)) + 
    order_likelihood(c(3,5)))
	```
	
We will firstly consider these observations in isolation, then later
combine them with ${\mathcal O}$ which we will take to be
(conditionally) independent.  The first step is to define a suitable
likelihood function for ${\mathcal I}$:q


```{r}	
(mH0 <- maxp(H))
loglik(indep(mH0),H)
```

Above, `mH0` corresponds to $H_0$.  Note the low but nonzero estimated
strength of `p1`.

Observe in passing that we may reject $H_z\colon p_1=0$
unconditionally: we can deduce using elementary arguments that the
likelihood of $H_z$ is zero: if $p_1=0$, then $p_4=0$ from the first
line, and then $p_1=0$ from line 2; then $p_3=0$ from line 3, $p_5=0$
from line 4 and finally $p_2=0$ from line 1.  Thus we can say for sure
that $H_z$ is incorrect and we may safely ignore it henceforth.

## Hypothesis 1

Hypothesis 1 is rather tricky so we will use the ersatz $H_{1'}\colon
p_1\geqslant p_4$ (we choose $p_4$ on the grounds of its low estimated
value).  Then

```{r}
n <- 5 # number of players
small <- 1e-3  # numerical necessity
(mH1 <- maxp(H,startp=c(small*2,rep(small,n-2)),fcm=rbind(c(1,0,0,-1)),fcv=0))
loglik(indep(mH1),H)
```

See how the constraint of $H_1$ is active, for at the evaluate
$p_1=p_4$ (the numerical value of `small` is immaterial).

## Hypothesis 2

```{r}
mH2 <- equalp(H)
loglik(indep(mH2),H)
```

## Support function


We can present a support function for $H_0,H_1,H_2$ for ${\mathcal
I}$:

```{r,suppcalculator}
Supp <- c(H0=loglik(indep(mH0),H), H1=loglik(indep(mH1),H), H2=loglik(indep(mH2),H)
)
Supp-max(Supp)
```

# Additional uninformative observation

Suppose we now make a perfectly uninformative observation: in an
independent trial, the order statistic for the five competitors was
one of the $5!=120$ possible orders.  How does this change our
relative support for $H_0$ against $H_1$ and $H_2$?  It should make no
difference.

```{r,uninformativesupportfunction}
library("partitions")
H # as before, here for convenience
M <- perms(5)   # uninformative!
SL <- list()
for(i in seq_len(ncol(M))){
	SL[[i]] <- H + order_likelihood(M[,i,drop=TRUE])
}
SL <- as.suplist(SL)
```

So `SL` is a compound object that gives a likelihood function for the
joint observation of the order statistics and the uninformative data a
subsequent (independent) trial was in any of the $5!=120$ possible
orders.  We can find the MLE for different observations:

```{r,mls0}
mSL0 <- maxp(SL)
mSL1 <- maxp(SL,startp=c(small*2,rep(small,n-2)),fcm=rbind(c(1,0,0,-1)),fcv=0)
mSL2 <- equalp(SL)
```

We use `like_single_list()` to calculate the likelihoods at the
different evaluates; note that this function returns likelihoods, not
supports.

```{r,supp2calc}
Supp2 <-
      log(c(
      H0 = like_single_list(indep(mSL0),SL),
      H1 = like_single_list(indep(mSL1),SL),
      H2 = like_single_list(indep(mSL2),SL)))
(Supp2 <- Supp2-max(Supp2))
```

which is identical to the previous support function.

# Additional weakly informative observation

Now we make another observation ${\mathcal O}$ which is independent of
${\mathcal I}$: person `1` did not win.  It is clear that observation
${\mathcal O}$ is only very weakly informative.  Package idiom is
similar to the perfectly uninformative observation considered above,
except that we remove every order that has person 1 winning:

```{r,slacalc}
M <- perms(5)
M <- M[, M[1,]!=1]  # remove any column with "1" in first place
SLa <- list()
for(i in seq_len(ncol(M))){
	SLa[[i]] <- H + order_likelihood(M[,i,drop=TRUE])
}
SLa <- as.suplist(SLa)
```

So `SLa` is a compound object that gives a support function for the
joint observation ${\mathcal I}$ and ${\mathcal O}$.  We can find the
MLE:

```{r,mlsa}
mSLa0 <- maxp(SLa)
mSLa1 <- maxp(SLa,startp=c(small*2,rep(small,n-2)),fcm=rbind(c(1,0,0,-1)),fcv=0)
mSLa2 <- equalp(SLa)
```

```{r,suppacalc}
Suppa <-
      log(c(
      H0 = like_single_list(indep(mSLa0),SLa),
      H1 = like_single_list(indep(mSLa1),SLa),
      H2 = like_single_list(indep(mSLa2),SLa)))
(Suppa <- Suppa-max(Suppa))
```

We can now compare the support function for ${\mathcal I}$ with the
support function for ${\mathcal I}$ and ${\mathcal H}$:

```{r,comparesups}
Supp2-Suppa
```

Thus ${\mathcal O}$ furnishes a tiny bit of extra evidence against
$H_1$ (about $0.016$ units of support) and a little bit of extra
evidence against $H_2$ (about $0.193$ units of support).
