---
documentclass: jss
author:
  - name: Robin K. S. Hankin
    affiliation: Auckland University of Technology
    address: >
      2-14 Wakefield Street
      Auckland, New Zealand
    email: \email{hankin.robin@gmail.com}
    url: http://aut.ac.nz/
title:
  formatted: "An Objective Assessment of Points Scorings in Formula 1 Motor Racing"
  plain:     "An Objective Assessment of Points Scorings in Formula 1 Motor Racing"
  # For running headers, if needed
  short:     "Formula 1 Points Scoring"
abstract: >
  The point scoring system of Formula 1 motor racing is a long-standing
  contention among fans and competitors, with changes to the points
  scored occurring frequently.  Here, I apply generalized Plackett-Luce
  likelihood functions to Formula 1 racing, and assess historical points
  scoring systems objectively.  In a well-defined sense, the points
  scoring system of 1985 is the best of the historical ones.  I make
  similar observations about related competitive situations including
  the Eurovision Song contest and XXX.
keywords:
  # at least one keyword must be supplied
  formatted: [keywords, not capitalized, "\\proglang{Java}"]
  plain:     [keywords, not capitalized, Java]
preamble: 
  \usepackage{amsmath}
output: rticles::jss_article
---



# Introduction

Formula 1 racing is an important and prestigious motor sport
\citep{moul2009}.  Season ranking is based on a points allocation
system wherein competitors are awarded points based on race finishing
order; points accumulate additively.  The overall competition winner
is the competitor who accumulates the most points after the final
race.

However, in the case of Formula 1 Motor Racing, the points system is
the subject of much controversy, having changed often since the
competition's inauguration in 1950 when the points allocation, used
from 1950 to 1959 was $(8,6,4,3,2)$, thus crediting only the first
five finishers.  As of 2020, the current system of
$(25,18,15,12,10,8,6,4,2,1)$ credits the first 10.  Arguably these two
systems could introduce different rational behaviour under zero-sum
assumptions: if, in a race, a driver knows he will place seventh under
a low-risk strategy but may place sixth by dint of driving more
aggressively, the low-risk strategy might be rational under the first
points system (which does not reward the extra ranking), but not under
the second, which does.  Still, it is reasonable to assume that each
driver strives to maximise his rank.

Given that racing is a zero-sum game---and that points are
monotonically decreasing---each player will try to get as high a rank
as possible regardless of the actual points system used.  However,
there are other consistent interpretations.  \cite{bakhrankova2011},
for example, considers the possibility of inter-driver collusion, a
phenomenon not pursued here; and authors such as
\citeauthor{mastromarco2009} suggest that the frequency of rule
changes is driven by factors such as driver safety and revenue
optimization.



Points systems similar to that of Formula 1 are common in other sports
and examples would include modern pentathlon, curling, chess, rowing,
and figure skating; all have the common feature of translating ranks
into scores which combine additively to generate an overall ranking.
Further, we see points systems frequently in the wider context of
competitive situations such as the Eurovision Song Contest, Australian
MasterChef, University rankings, educational league tables, car safety
ratings, and many others.

## Bradley-Terry and generalizations for rank statistics

The Bradley-Terry model \citep{bradley1952} assigns non-negative
strengths $p_1,\ldots, p_n$ to each of $n$ competitors in such a way
that the probability of $i$ beating $j\neq i$ in pairwise competition
is $\frac{p_i}{p_i+p_j}$; it is conventional to normalize so that
$\sum p_i=1$.  Further, we use a generalization due to
\citet{luce1959}, in which the probability of competitor $i$ winning
in a field of $j=1,\ldots, n$ is $\frac{p_i}{p_1+\cdots +p_n}$.
Noting that there is information in the whole of the finishing order,
not just the first across the line, we can follow \cite{plackett1975}
and consider the runner-up to be the winner among the remaining
competitors; and so on down the finishing order.  Without loss of
generality, if the order of finishing were $1,2,3,4,5$, then a suitable
\citeauthor{plackett1975} likelihood function would be

\begin{equation}\label{competitors_1_to_5_likelihood}
\frac{p_1}{p_1+p_2+p_3+p_4+p_5}\cdot
\frac{p_2}{p_2+p_3+p_4+p_5}\cdot
\frac{p_3}{p_3+p_4+p_5}\cdot
\frac{p_4}{p_4+p_5}\cdot
\frac{p_5}{p_5}
\end{equation}

and a slight generalization of this would allow the incorporation of
non-finishers (DNF etc).  If, say, competitors 4 and 5 did not finish,
we would have

\begin{equation}\label{competitors_1_to_3_only_finished}
\frac{p_1}{p_1+p_2+p_3+p_4+p_5}\cdot
\frac{p_2}{p_2+p_3+p_4+p_5}\cdot
\frac{p_3}{p_3+p_4+p_5}
\end{equation}

(observe how this likelihood function, while informative about
$p_4+p_5$, is uninformative about $p_4\left|p_4+p_5\right.$).  We now
use a technique due to \cite{hankin2010,hankin2017} and introduce
fictional (reified) entities whose nonzero Bradley-Terry strength
helps certain competitors or sets of competitors under certain
conditions.  The canonical example would be the home-ground advantage
in association football.  If players (teams) $1,2$ with strengths
$p_1,p_2$ compete, and if our observation were $a$ home wins and $b$
away wins for team $1$, and $c$ home wins and $d$ away wins for team
$2$, then a suitable likelihood function would be

\[
\left(\frac{p_1+p_H}{p_1+p_2+p_H}\right)^a
\left(\frac{p_1}{p_1+p_2+p_H}\right)^b
\left(\frac{p_2+p_H}{p_1+p_2+p_H}\right)^c
\left(\frac{p_2+p_H}{p_1+p_2+p_H}\right)^d
\]

where $p_H$ is a quantification of the beneficial home ground effect.
Similar techniques have been used to account for the first-move
advantage in chess, and effective coordination between members of
doubles tennis teams; we may use a similar device to account for pole
position in Formula 1.  Here I analyse racing results from the 2017
season using the `hyper2` package \citep{hankin2017} which implements
the Plackett-Luce likelihood function with additional reified
entities.

# Formula 1 dataset


Here we use the results from 2017:

\small
\begin{CodeChunk}
\begin{CodeOutput}
           AUS CHN BHR RUS ESP MON CAN AZE AUT GBR HUN BEL ITA SIN MAL JPN USA MEX BRA ABU
Hamilton     2   1   2   4   1   7   1   5   4   1   4   1   1   1   2   1   1   9   4   2
Vettel       1   2   1   2   2   1   4   4   2   7   1   2   3 Ret   4 Ret   2   4   1   3
Bottas       3   6   3   1 Ret   4   2   2   1   2   3   5   2   3   5   4   5   2   2   1
Raikkonen    4   5   4   3 Ret   2   7  14   5   3   2   4   5 Ret DNS   5   3   3   3   4
Ricciardo  Ret   4   5 Ret   3   3   3   1   3   5 Ret   3   4   2   3   3 Ret Ret   6 Ret
...
Hartley      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13 Ret Ret  15
Button       0   0   0   0   0 Ret   0   0   0   0   0   0   0   0   0   0   0   0   0   0
Resta        0   0   0   0   0   0   0   0   0   0 Ret   0   0   0   0   0   0   0   0   0
\end{CodeOutput}
\end{CodeChunk}



```{r,echo=FALSE,print=FALSE}
top <- 11
points_inaugural <- c(8,6,4,3,2)
```

Each row is a driver and each column (after the first) a venue.  We
see that Hamilton, the first row, came second in Australia, first in
China, second in Bahrain, fourth in Russia, and so on (Hartley,
Button, and Resta placed last).  In the first column, we see the
result from Australia (AUS) in which Hamilton came second, Vettel
first, Bottas third, and so on.  Notation used also includes six
different classes of no-score such as `Ret` for retired, `WD` for
withdrawn, and so on; a zero entry means "did not finish".  It is
straightforward to translate this table into a Plackett-Luce
log-likelihood function using the `hyper2` package; for simplicity we
will consider only the `r top` top-ranked drivers\footnote{In the
Plackett-Luce likelihood function, the performance of lower-ranked
players can be weakly informative about higher-ranked players'
strengths.  For example, we see that Vettel retired twice (in
Singapore and Japan), so any player who placed in those venues will
effectively ``steal'' strength from Vettel, and generally ``give'' it
to Hamilton or Bottas.}.  Although it has many terms, the overall loglikelihood 
expression is of the general form

```{r,label=showanordertableandhead,echo=FALSE,print=FALSE}
library(hyper2,quietly=TRUE)
top <- 11
H <- ordertable2supp(F1_table_2017[seq_len(top),])
```

\newcommand{\pham}{p_\mathrm{Ham}}
\newcommand{\pvet}{p_\mathrm{Vet}}
\newcommand{\pbot}{p_\mathrm{Bot}}
\newcommand{\prai}{p_\mathrm{Rai}}
\newcommand{\pric}{p_\mathrm{Ric}}
\newcommand{\pver}{p_\mathrm{Ver}}
\newcommand{\pper}{p_\mathrm{Per}}
\newcommand{\poco}{p_\mathrm{Oco}}
\newcommand{\psai}{p_\mathrm{Sai}}
\newcommand{\phul}{p_\mathrm{Hul}}
\newcommand{\pmas}{p_\mathrm{Mas}}

\begin{equation}
\frac{\pham^{20}\,\pmas^{16}\,\pbot^{19}\ldots
}{\parbox{4in}{$(\pper+\poco)(\pver+\pper+\psai+\phul+\pmas)\\
\rule{10mm}{0mm}(\pric+\pper+\pmas)(\psai+\pmas)\\ \rule{20mm}{0mm}
         (\pver + \pper+ \poco + \psai+ \phul)\ldots
	 $}}
 \end{equation}



Finding the maximum likelihood estimate for the players' strengths is
straightforward.  The `hyper2` package includes a suite of numerical
optimization routines, and because they have access to derivatives,
convergence is rapid.  A graphical illustration of the strengths is
given in figure \ref{piechartstrength}

```{r,label=printapiechart,echo=FALSE,fig.cap="Maximum likelihood estimates \\label{piechartstrength} of the strengths of the top-ranked 11 drivers in the 2017 Formula 1 season"}
mH <- maxp(H)
mH
pie(maxp(H)[c(1,6,11,2,7,3,8,4,9,5,10)])
```

We see the Hamilton has the largest estimated strength (at about
0.39), followed by Vettel and then Bottas at about 0.2 and 0.13
respectively.  However, it should be noted that a likelihood ratio
test [`samep.test()`, supplied with the package] does not reject the
null that Hamilton and Vettel have the same strength ($H_0\colon
\pham= \pvet$) with a likelihood ratio of $e^{1.5}\simeq 4.48$,
corresponding (by Wilks's theorem) to an asymptotic $p$-value of about
$0.08$.

```{r,label=dosameptest, echo=FALSE, print=FALSE, cache=TRUE}
ignore <- samep.test(H,1:2)
```

## Likelihood scoring vs points scoring

The points scored by each driver give a ranking shown in the table;
but Plackett-Luce likelihoods also give a ranking that does not depend
on any arbitrary points system.  We can plot one ranking against the
other:

```{r, label=calcpoints, echo=FALSE, cache=TRUE}
p <- c(25, 18, 15, 12, 10, 8, 6, 4, 2, 1, 0, 0)
points_real <- p
points_inaugural <- c(8,6,4,3,2)
dp <- ordertable2points(as.ordertable(F1_table_2017[seq_len(top),]),p)
dp <- sort(dp,decreasing=TRUE)
dp[] <- seq_along(dp)
m <- maxp(H)
m <- sort(m,decreasing=TRUE)
m[] <- seq_along(m)
```

(note carefully that the historically correct points awarded to the
drivers differs from that calculated here.  That is for two reasons:
firstly, ``fastest lap'' points are not included here, and also the
truncation of the order table to the first 11 drivers can increase the
rank of a driver if non-first-11 drivers are placed).

```{r,label=likevspoints,cache=TRUE,echo=FALSE,fig.cap="Ordering of the \\label{orderingbypointsandlikelihood} top-ranked 11 drivers in the 2017 Formula 1 season.  Horizontal axis gives official (points-based) order, and the vertical axis gives the likelihood horder.    Thus the points-based ordering would be Hamilton, Vettel, R\"{a}ikk\"{o}nen YES I KNOW IT IS WRONG: RMARKDOWN IS DEFECTIVE while the likelihood ordering is (reading vertically) Hamilton, Vettel, Bottas"}
par(pty='s')        # square plot
ox <- dp
oy <- ordertrans(m,dp)
plot(ox,oy,asp=1,pty='s',xlim=c(0,11.2),ylim=c(0,11.2),pch=16,
    xlab="official order",ylab="my order",main='Formula 1, 2017 season')
par(xpd=TRUE)       # allow drivers' names to appear outside plotting region
for(i in seq_along(ox)){text(ox[i],oy[i],names(ox)[i],pos=4,col='gray') }
par(xpd=FALSE)      # stop diagonal line from protruding beyond plotting region
abline(0,1)
```

From figure \ref{orderingbypointsandlikelihood}, we see that the
first two drivers (Hamilton, Vettel) are are respectively first and
second according to both ranking ranking procedures; but
R\"{a}ikk\"{o}nen YES I KNOW IT IS WRONG: RMARKDOWN IS DEFECTIVE and
Bottas are third and fourth, and fourth and third, according to points
and likelihood respectively.  The degree of agreement between the two
systems might be quantified as "two", for the positions of the top two
drivers agree.

Observing that both the likelihood ranking and the points ranking are
random variables suggests a method whereby we can objectively assess a
given points system.  Using sampling techniques we can repeatedly
generate an order table \emph{in silico}, using estimated driver
strengths from the observed 2017 table.  For each of, say, 1000 such
synthetic tables, calculate drivers' maximum likelihood
\citeauthor{plackett1975} strengths, and also their points awarded
according to any given points system.  We then compare rankings
generated by the \citeauthor{plackett1975} strengths and the points
awarded and note the degree of agreement between the two.  This
furnishes an objective assessment of the points system used.

## Points systems

Here we follow the above protocol to assess different points systems.
There are a number of plausible points systems that might be used:

\begin{itemize}
\item Equal points to the top $r$ competitors
$(\underbrace{1,1,\ldots ,1}_{r},0,0,\ldots)$, noting that
$r=1$ corresponds to a ``winner takes all'' system
\item Linear decrease $(r,r-1,r-2,\ldots,3,2,1,0)$ for integer $0<r<n$
\item Exponential decay $(1,r,r^2,r^3,\ldots)$ for some fixed $r<1$
\item Zipf's law $(1,1/2,1/3,1/4,\ldots)$
\item The current Formula 1 system $(25,18,15,12,10,8,6,4,2,1)$
\item The inaugural Formula 1 system $(8,6,4,3,2)$
\end{itemize}

Applying the current points system, for example, to the 2017 table we
would rank the drivers as follows:

```{r,label=realpointsshower,echo=FALSE}
real <- ordertable2points(ranktable_to_ordertable(wikitable_to_ranktable(F1_table_2017)),p)
real <- round(real[seq_len(top)],2)
real <- sort(real,decreasing=TRUE)
real[] <- seq_along(real)
real
```

(this happens to be identical to the ranking after the extra point was
awarded for fastest lap).  However, if we were to use Zipf's law, the
ranking would be:

```{r,label=zipfpointsshower,echo=FALSE}
zipf <- ordertable2points(ranktable_to_ordertable(wikitable_to_ranktable(F1_table_2017)),1/seq_len(top))
zipf <- round(zipf[seq_len(top)],2)
zipf <- sort(zipf,decreasing=TRUE)
zipf[] <- seq_along(zipf)
zipf
```

Thus these two systems agree on the first three places but fourth is
awarded to Raikkonen under the F1 system and Ricciardo under Zipf.

Now compare the likelihood ranking:

```{r,label=likelihoodrankingshower,echo=FALSE}
jj <- mH
jj <- sort(jj,decreasing=TRUE)
jj[] <- seq_along(jj)
jj
```

# Numerical results

We now assess the various points systems discussed above, using 1000
_in silico_ trials.

```{r,label=definemultiplemontecarlo, echo=FALSE}
top <- 11
f2017 <- read.table("formula1_2017.txt",header=TRUE)[seq_len(top),1:20]
m <- maxp(ordertable2supp(as.ordertable(f2017)))

## Now work on synthetic dataset generation:
resampling_multiple <- function(m,f2017,pointslist){
    random_table <- rrank(n=ncol(f2017), p=m)
    rownames(random_table) <- colnames(f2017)
    ## "random_table" is a random table; now calculate lstar and pstar for
    ## likelihood ranks and points ranks respectively:

    l_star <- maxp(ordertable2supp(ranktable_to_ordertable(random_table)))
    l_star[] <- seq_along(l_star)
    ## l_star is the likelihood order statistic.

	goodnesses <- seq_along(pointslist)
	for(i in seq_along(pointslist)){
		p_star <- ordertable2points(as.ordertable(ranktable_to_ordertable(random_table)),pointslist[[i]])
		p_star <- sort(p_star,decreasing=TRUE)
		p_star[] <- seq_along(p_star)
		goodness <- sum(cumprod(names(p_star)==names(l_star)))
		goodnesses[i] <- goodness
		}
	return(goodnesses)
}
pointslist <- list(
	real = points_real,
	inau = points_inaugural,
	top1 = rep(1,1),
	top2 = rep(1,2),
	top3 = rep(1,3),
	top4 = rep(1,4),
	top5 = rep(1,5),
	top6 = rep(1,6),
	top7 = rep(1,7),
	top8 = rep(1,8),
	top9 = rep(1,9),
	topt = rep(1,10),  # effectively punishing the last finisher
   	lin1 = 1,   # same as top1
	lin2 = 2:1,
	lin3 = 3:1,
	lin4 = 4:1,
	lin5 = 5:1,
	lin6 = 6:1,
	lin7 = 7:1,
	lin8 = 8:1,
	lin9 = 9:1,
	lint = 10:1,
	line = 11:1,
	zipf = 1/seq_len(top),
	expa = 1/1.01^seq_len(top),
	expb = 1/1.10^seq_len(top),
	expc = 1/1.20^seq_len(top),
	expd = 1/1.50^seq_len(top),
	exp2 = 1/2^seq_len(top),
	exp3 = 1/3^seq_len(top),
	exp4 = 1/4^seq_len(top),
	fis1 = c(1,1,1),
	fis2 = c(1,1,0.9),
	fis3 = c(1,1,1,0.1),
	fis4 = c(1,1,0.9,0.1),
	fis5 = c(1,1,0.5),
	fis6 = c(1,1,1,0.5),
	fis7 = c(1,1,0.5,0.5)
)
```

```{r,label=multiplemontecarloexecute, cache=TRUE,echo=FALSE}
set.seed(9)
f2017 <- read.table("formula1_2017.txt",header=TRUE)[seq_len(top),1:20]
m <- maxp(ordertable2supp(as.ordertable(f2017)))
OO <- replicate(1000,resampling_multiple(m,f2017,pointslist=pointslist))
```

now some summaries:

```{r,label=somesummaries}
summarytable <- data.frame(
means = apply(OO,1,mean),
winner_correct = rowSums(OO>1),
all_correct = rowSums(OO==top))
rownames(summarytable) <- names(pointslist)
summarytable
```



```{r,fig=TRUE}
typecol <- c(rep("red",2),rep("orange",10),rep("blue",11),rep("orange",1),rep("black",7),rep("gray",7))
plot(summarytable[,1],ylab='mean',pch=16,col=typecol)
plot(summarytable[,2],ylab='prob of winner correct',pch=16,col=typecol)
plot(summarytable[,3],ylab='prob. of total rank order correct',pch=16,col=typecol)
```


and visual:

```{r,label=plotcumulativeM,fig=TRUE}
o <- t(apply(1+OO,1,tabulate))
#matplot(0:11,apply(o[,12:1],1,cumsum)/1e3,type='b',lty=1,pch=16,ylab='probability',axes=FALSE,xlab='number incorrect')
jj <- c(0,2,4,6,8,11)
#axis(1,pos=0,at=jj,labels=c("0",paste("<=",jj[-1],sep="")))
#axis(2)
```

```{r,makeatable}
table(real_winner_ok=OO[1,]>0,top3_winner_ok=OO[3,]>0)
save(OO,file="~/rstudio/hyper2/inst/cache_results_2017.Rd")
```

Consider the first column of the table above which shows the number of
virtual races in which each scoring system gets the winner incorrect;
a good points system has a low value here.  Note that `top3` has by
far the lowest number, a finding which I have no explanation for.

# Discussion

Points systems are a source of lively debate from many perspectives.
The point of a point allocation system is to rank competitors in an
objective way; but 


Here I treat total points scored as a random variable and compare
different point allocation schemes against both one another and


but until now there is no objective way of comparing points systems.
if one considers order tables to be a random variable.  Because the
numerical value of points awarded for first, second, third etc, does
not affect driver behaviour it is a reasonable requirement that

Here, I assess
several plausible points systems including the one actually used in
Formula 1.  By several criteria, the 




\bibliography{chess}
