---
title: "Public perception of climate change"
author: "Robin K. S. Hankin"
date: "`r Sys.Date()`"
vignette: |
  %\VignetteIndexEntry{icons}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


This short document analyses the climate change dataset originally
presented in the hyperdirichlet R package^[RKS Hankin 2010.  "A
generalization of the Dirichlet distribution", *Journal of Statistical
Software*, 33:11] but using the hyper2 package instead.  Lay
perception of climate change is a complex and interesting process^[SC
Moser and L Dilling 2007.  "Creating a climate for change:
communicating climate change and facilitating social change".
Cambridge University Press] here we assess the engagement of
non-experts by the use of "icons" (this word is standard in this
context.  An icon is a "representative symbol") that illustrate
different impacts of climate change.

Here we analyse results of one experiment^[S. O'Neill 2007. "An Iconic
Approach to Representing Climate Change", School of Environmental
Science, University of East Anglia], in which subjects were presented
with a set of icons of climate change and asked to identify which of
them they find most concerning.  Six icons were used: PB [polar bears,
which face extinction through loss of ice floe hunting grounds], NB
[the Norfolk Broads, which flood due to intense rainfall events], L
[London flooding, as a result of sea level rise], THC [the
thermo-haline circulation, which may slow or stop as a result of
anthropogenic modification of the water cycle], OA [oceanic
acidification as a result of anthropogenic emissions of ${\mathrm
C}{\mathrm O}_2$], and WAIS [the West Antarctic Ice Sheet, which is
rapidly calving as a result of climate change].

Methodological constraints dictated that each respondent could be
presented with a maximum of four icons.  The R idiom below (dataset
```icons``` in the package) shows the experimental results.

```{r}
M <- matrix(c(
    5 , 3 , NA,  4, NA,   3,
    3 , NA,  5,  8, NA,   2,
    NA,  4,  9,  2, NA,   1,
    10,  3, NA,  3,  4,  NA,
    4 , NA,  5,  6,  3,  NA,
    NA,  4,  3,  1,  3,  NA,
    5 ,  1, NA, NA,  1,   2,
    5 , NA,  1, NA,  1,   1,
    NA,  9,  7, NA,  2,   0)
  , byrow=TRUE,ncol=6)
colnames(M) <- c("NB","L","PB","THC","OA","WAIS")
M
```

(M is called ```icons_matrix``` in the package).  Each row of ```M```
corresponds to a particular cue given to respondents.  The first row,
for example, means that a total of $5+3+4+3=15$ people were shown
icons NB, L, TCH, WAIS [column names of the the non-NA entries]; 5
people chose NB as most concerning, 3 chose L, and so on.  The dataset
is more fully described in the hyperdirichlet package.  To recreate
the ```icons``` likelihood function in the ```hyper2``` package, we
use the ```saffy()``` function:

```{r}
library("hyper2",quietly=TRUE)
icons <- saffy(M)
icons
```

At this point, the ```icons``` object as created above is
mathematically identical to ```icons``` object in the hyperdirichlet
package (and indeed the hyper2 package), but the terms might appear in
a different order.

## Analysis of the icons dataset

The first step is to find the maximum
likelihood estimate for the ```icons``` likelihood:

```{r}
mic <- maxp(icons)
mic
dotchart(mic,pch=16)
```

We also need the log-likelihood at an unconstrained maximum:

```{r}
L1 <- loglik(indep(mic),icons)
L1
```

Agreeing to 4 decimal places with the value given in the
hyperdirichlet package.

The next step is to assess a number of hypotheses concerning the
relative sizes of $p_1$ through $p_6$.

# Hypothesis testing.

Below, I investigate a number of hypotheses about $p_1,\ldots, p_6$.
The general analysis proceeds as follows; we can use $p_1>1/6$ as an
example but the method applies to any observation with a natural
one-sided alternative.

* We have an observation ${\mathcal O}$ 
wish to quantify the strength of evidence to support this.
* Translate our observation into a hypothesis phrased in terms as a
 restriction on parameter space.
* Divide the parameter space into two exclusive and exhaustive regions,
one of which corresponds to our statement and the other to its
negation.  For example, we might have $H_A\colon p_1>1/6$ and
$\overline{H_A}\colon p_1\leqslant 1/6$.
* Define a Null hypothesis corresponding to no restriction on the
  probability simplex.  We write $H_0\colon\sum p_i=1$ and observe that
  $H_0=H_A\cup \overline{H_A}$. 
* We then attempt to reject $\overline{H_A}$:  to do this we perform two
  likelihood maximizations: one unconstrained, corresponding
  to $H_0$, and one constrained, corresponding to $\overline{H_A}$.
* We calculate ${\mathcal L}_{H_0} :=\operatorname{argmax}_{p\in
  H_0}{\mathcal L}(p)$ and ${\mathcal L}_{H_A} :=
  \operatorname{argmax}_{p\in H_A}{\mathcal L}(p)$ and observe that 
  ${\mathcal O}$ implies the strict inequality
  ${\mathcal L}_{H_0} > {\mathcal L}_{H_A}$.
* Calculate the likelihood ratio
  $R={\mathcal L}_{H_0}/{\mathcal L}_{H_A}>1$ or equivalently the
  _support_ for $H_A$, $\Lambda = \log R>0$.
* To assess $H_A$, we determine $d$, the number of degrees of freedom
inherent in $H_A$.
* We may either use Edwards's criterion of two units of support per
  degree of freedom, or Wilks's theorem that, under the null,
  $2\Lambda\sim\chi^2_d$.
* If the criterion is met we may reject $\overline{H_A}$ and infer
  that $H_A$ is the case.

## Hypothesis 1: $p_1 > 1/6$

Following the analysis in Hankin 2010, and restated above, we first
observe that NB [the Norfolk Broads] is the icon with the largest
estimated probability with $\hat{p_1}\simeq 0.25$ (O'Neill gives a
number of theoretical reasons to expect $p_1$ to be large).  This
would suggest that $p_1$ is in fact large, in some sense, and here I
show how to assess this statement statistically.  Consider the
hypothesis $H_A\colon p_1>1/6$, and as per the protocol above we will
try to reject $\overline{H_A}\colon p_1\leqslant 1/6$.

To that end, we perform a constrained optimization, with (active)
constraint that $p_1\leqslant 1/6$ and note the support at the
evaluate.  We then compare this support with the support at the
unconstrained evaluate; if the difference in support is large then
this constitutes strong evidence for $H_A$ and then would conclude
that $p_1 > 1/6$.  In package idiom, the optimization is most easily
done by imposing additional constraints to the `maxp()` function via
the `fcm` and `fcv` arguments:

```{r}
small <- 1e-4  #  ensure start at an interior point
maxlike_constrained <- 
    maxp(icons, startp=indep(equalp(icons))-c(small,0,0,0,0),
         give=TRUE, fcm=c(-1,0,0,0,0),fcv= -1/6)
maxlike_constrained	 
```	

Note that the value of $p_1$ is equal to $1/6$: the maximum is on the
boundary of the admissible region.  The extra support is given by

```{r}
ES <- L1-maxlike_constrained$value 
ES
```

(compare 2.608181 from the hyperdirichlet package).  This exceeds
Edwards's two-units-of-support criterion; a $p$-value would be

```{r}
pchisq(2*ES,df=1,lower.tail=FALSE)
```

both of which would indicate that we may reject that hypothesis that
$p_1\leqslant 1/6$ and thereby infer $p_1>\frac{1}{6}$.

## Hypothesis 2: $p_1\geqslant\max\left(p_2,\ldots,p_6\right)$

Another constrained likelihood maximization, although this one is not
possible with convex constraints.  In the language of the generic
procedure given above, we would have

\[
H_A\colon 
(p_1 > p_2)\cap
(p_1 > p_3)\cap
(p_1 > p_4)\cap
(p_1 > p_5)\cap
(p_1 > p_6)
\]

\[
\overline{H_A}\colon 
(p_1\leqslant p_2)\cup
(p_1\leqslant p_3)\cup
(p_1\leqslant p_4)\cup
(p_1\leqslant p_5)\cup
(p_1\leqslant p_6)
\]

We have to compare `L1` against the maximum likelihood over the region
defined by $\overline{H_A}$, that is, $p_1$ being greater than *at
least one* of $p_2,\ldots,p_6$.  The union of convex sets is not
necessarily convex (think two-way Venn diagrams).  As far as I can
see, the only way to do it is to perform a sequence of five
constrained optimizations: $p_1\leqslant p_2, p_1\leqslant p_3,
p_1\leqslant p_4, p_1\leqslant p_5$.  The fillup constraint would be
$p_1\leqslant p_6\longrightarrow 2p_1+p_2+\ldots p_5\leqslant 1$.  We
then choose the largest likelihood from the five.

```{r}
o <- function(Ul,Cl,startp,give=FALSE){
    small <- 1e-4  #  ensure start at an interior point
    if(missing(startp)){startp <- small*(1:5)+rep(0.1,5)}			
    out <- maxp(icons, startp=small*(1:5)+rep(0.1,5), give=TRUE, fcm=Ul,fcv=Cl)
    if(give){
        return(out)
    }else{
        return(out$value)
    }
}

p2max <- o(c(-1, 1, 0, 0, 0), 0)  # p1 <= p2
p3max <- o(c(-1, 0, 1, 0, 0), 0)  # p1 <= p3
p4max <- o(c(-1, 0, 0, 1, 0), 0)  # p1 <= p4
p5max <- o(c(-1, 0, 0, 0, 1), 0)  # p1 <= p5
p6max <- o(c(-2,-1,-1,-1,-1),-1)  # p1 <= p6 (fillup)
```

(the final line is different because $p_6$ is the fillup value).

```{r}
likes <- c(p2max,p3max,p4max,p5max,p6max)
likes
ml <- max(likes) 
ml
```

Thus the first element of `likes` corresponds to the maximum
likelihood, constrained so that $p_1\leqslant p_2$; the second element
corresponds to the constraint that $p_1\leqslant p_3$, and so on.  The
largest likelihood is the easiest constraint to break, in this case
$p_1\leqslant p_3$: this makes sense because $p_3$ has the second
highest MLE after $p_1$.  The extra likelihood is given by

```{r}
L1-ml
```

(the hyperdirichlet package gives 0.0853 here, a suprisingly small
discrepancy given the difficulties of optimizing over a nonconvex
region).  We conclude that there is no evidence for
$p_1\geqslant\max\left(p_2,\ldots,p_6\right)$.

It's worth looking at the evaluate too:

```{r}
o2 <- function(Ul,Cl){
  jj <-o(Ul,Cl,give=TRUE)
  out <- c(jj[[1]],1-sum(jj[[1]]),jj[[2]])
  names(out) <- c("p1","p2","p3","p4","p5","p6","support")
  return(out)
}
rbind(
o2(c(-1, 1, 0, 0, 0), 0),  # p1 <= p2
o2(c(-1, 0, 1, 0, 0), 0),  # p1 <= p3
o2(c(-1, 0, 0, 1, 0), 0),  # p1 <= p4
o2(c(-1, 0, 0, 0, 1), 0),  # p1 <= p5
o2(c(-2,-1,-1,-1,-1),-1)   # p1 <= p6
)
```

In the above, the evaluate is the first five columns ($p-6$ being the
fillup) and the final column is the log-likelihood at the evaluate.
See how the constraint is active in each line: `M[1,] == M[1:5,2:6]`.
Also note that the largest log-likelihood is the second row: if we
were to violate any of the constraints, it would be $p_1<p_3$,
consistent with the fact that $p_3$ (polar bears) has the second
highest strength, after $p_1$.

## Low frequency responses

The next hypothesis follows from the observed smallness of $\hat{p_5}$
(ocean acidification) and $\hat{p_6}$ (West Antarctic Ice Sheet) at
0.111 and 0.069 respectively.  These two strengths correspond to
"distant" concerns and O'Neill had reason to consider their sum (which
she argued would be small).  Thus we specify H_A\colon p_5+p_6 <
\frac{1}{3}$ and $\overline{H_A}\colon p_5+p+6\geqslant\frac{1}{3}$.


The optimizing constraint of $p_5+p_6\geqslant\frac{1}{3}$ translates
to an operational constraint of
$-p_1-p_2-p_3-p_4\geqslant-\frac{2}{3}$ (because
$p_5+p_6=1-p_1-p_2-p_3-p_4$):

```{r} 
jj <- o(c(-1,-1,-1,-1,0) , -2/3, give=TRUE,start=indep((1:6)/21))$value
jj
```

then the extra support is 

```{r}
L1-jj
```

(compare 7.711396 in hyperdirichlet, not sure why the discrepancy is
so large).

## Final example

The final example was motivated by the fact that both the distant
icons $p_5$ and $p_6$ had lower strength than any of the local icons
$p_1\ldots p_4$.  Thus we would have $H_A\colon
\max\left\{p_5,p_6\right\}<\min\left\{p_1,p_2,p_3,p_4\right\}$.  This
means the optimization is constrained so that *at least one* of
$\left\{p_5,p_6\right\}$ exceeds *at least one* of
$\left\{p_1,p_2,p_3,p_4\right\}$.  So we have the union of the various
possibilities:

\[
\overline{H_A}\colon
\bigcup_{j\in\left\{5,6\right\}\atop k\in\left\{1,2,3,4\right\}}
\left\{\left(p_1,p_2,p_3,p_4,p_5,p_6\right)\left|\sum p_i=1,
p_j\geqslant p_k\right.\right\}
\]

and of course $p_6\geqslant p_2$, say, translates to
$-p_1-2p_2-p_3-p_4-p_5\geqslant -1$.

```{r}
start <- indep(c(small,small,small,small,0.5-2*small,0.5-2*small))
jj <- c(
   o(c(-1, 0, 0, 0, 1), 0,start=start),
   o(c( 0,-1, 0, 0, 1), 0,start=start),
   o(c( 0, 0,-1, 0, 1), 0,start=start),
   o(c( 0, 0, 0,-1, 1), 0,start=start),

   o(c(-2,-1,-1,-1,-1),-1,start=start),
   o(c(-1,-2,-1,-1,-1),-1,start=start),
   o(c(-1,-1,-2,-1,-1),-1,start=start),
   o(c(-1,-1,-1,-2,-1),-1,start=start)
   )
jj
max(jj)
```

So the extra support is

```{r}
L1-max(jj)
```
(compare hyperdirichlet which gives 3.16, not sure why the difference).
We should look at the maximum value:

```{r}
   o(c( 0, 0, 0,-1, 1), 0,give=TRUE,start=start)
```

So the evaluate is at the boundary, for $p_4=p_5$.  I have no
explanation for the discrepancy between this and that in the
hyperdirichlet package.
